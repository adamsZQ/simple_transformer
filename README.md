# transformer
尝试使用allennlp和torch原生写了两个版本的transformer，其中allennlp版本没有使用各种trick，同时缺少evaluation部分。

torch版本相对完整，代码修改于:http://nlp.seas.harvard.edu/2018/04/03/attention.html 哈佛NLP版本的Annotated Transformer